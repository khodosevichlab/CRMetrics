---
title: "Analysis of 10x test data"
output: 
  github_document:
    toc: true
---

# Preparations

We have selected [publicly available datasets](https://www.10xgenomics.com/resources/datasets) from 10x which can be downloaded [here](http://kkh.bric.ku.dk/rasmus/crmetrics_testdata.tar.gz). You can download the zipped data using wget or curl, e.g. 
`wget http://kkh.bric.ku.dk/rasmus/crmetrics_testdata.tar.gz`, and then unpack using 
`tar -xvf crmetrics_testdata.tar.gz`

# Initializing a CRMetrics class

Load the library

```{r setup, message=FALSE}
library(CRMetrics)
library(magrittr)
library(dplyr)
```

Initialize a new object of class `CRMetrics` with the path to the Cell Ranger output and a metadata file. Here, the folder with our test data is stored in `/data/ExtData/`.
Metadata can be added in the initialization call from a comma-separated file. The metadata file contains a column `sample` with the samples and optionally more columns with factors. Only sample IDs in column `sample` will be included.

```{r}
crm <- CRMetrics$new(data_path = "/data/ExtData/CRMetrics_testdata/", 
                     metadata = "/data/ExtData/CRMetrics_testdata/metadata.csv", 
                     n.cores = 50)
```

We can review our metadata

```{r}
crm$metadata
```

# Plot summary statistics

We can investigate which metrics are available and choose the ones we would like to plot

```{r}
crm$selectMetrics()
```


## Samples per condition

First, we can plot the number of samples per condition. Here, we investigate how the distribution of the 10x Chromium chemistry differs between the throughput (resolution) of the 10x kits where LT is short for low throughput.

```{r warning=FALSE}
crm$plotSummaryMetrics(comp_group = "chemistry", metrics = "samples per group", second_comp_group = "resolution")
```

## Metrics per sample

In one plot, we can illustrate selected metric summary stats. If no comparison group is set, it defaults to `sample`. We note that `donorC_3k` was counted with an old version of Cell Ranger and therefore does not contain all metrics.

```{r fig.width=12, fig.height=12, warning=FALSE}
metrics.to.plot <- crm$selectMetrics(ids = c(1:4,6,18,19))
crm$plotSummaryMetrics(metrics = metrics.to.plot, 
                       plot_geom = "point")
```

## Metrics per condition

We can do the same, but set the comparison group to `chemistry`. This will add statistics to the plots. Additionally, we can add a second comparison group for coloring.

```{r fig.width=12, fig.height=10, warning=FALSE}
crm$addComparison("chemistry")
crm$plotSummaryMetrics(metrics = metrics.to.plot, 
                       plot_geom = "point", 
                       stat_test = "non_parametric",
                       second_comp_group = "cellranger")
```

## Metrics per condition with >2 levels

For the sake of the example, we change Cell Ranger versions for samples before v. 3 to "<3.0.0". This will provide us with three comparisons groups to exemplify how to use automated statistics for such situations.

```{r, fig.width=12, fig.height=10}
crm$metadata$cellranger %<>% 
  as.character() %>% 
  {c(.[c(1,2)],rep("<3.0.0",2),.[c(5,6)])} %>% 
  factor()

crm$plotSummaryMetrics(comp_group = "cellranger",
                       metrics = metrics.to.plot, 
                       plot_geom = "point", 
                       stat_test = "non_parametric",
                       second_comp_group = "chemistry", 
                       secondary_testing = TRUE)
```


## Metrics per condition with numeric covariate

For the sake of the example, we add a numeric vector to our metadata. Then, we can choose a numeric comparison group which will add regression lines to the plots.

```{r fig.height=10, fig.width=12}
crm$metadata$num.vec <- c(4,3,4,3,4,6) %>% as.numeric()

crm$plotSummaryMetrics(comp_group = "num.vec",
                       metrics = metrics.to.plot, 
                       plot_geom = "point",
                       second_comp_group = "chemistry",
                       se = FALSE)
```

We see that there's a significant effect of the numeric vector on `Mean Reads per Cell`. Let us investigate `Mean Reads per Cell` closer by performing regression analyses for both conditions of `chemistry`.

```{r}
crm$plotSummaryMetrics(comp_group = "num.vec",
                       metrics = "Mean Reads per Cell", 
                       plot_geom = "point",
                       second_comp_group = "chemistry", 
                       group_reg_lines = TRUE)
```

We see that there is no significant effect of the numeric vector on neither of the chemistries although the R2 values are high.

# Add detailed metrics

We can read in count matrices to assess detailed metrics.

```{r}
crm$addDetailedMetrics()
```

The horizontal lines indicates the median values for all samples.

```{r}
metrics.to.plot <- crm$detailed_metrics$metric %>%
  unique()
crm$plotDetailedMetrics(metrics = metrics.to.plot, 
                        plot_geom = "violin")
```

# Embed cells using Conos and UMAP

In order to plot our cells in a UMAP embedding, we need to perform preprocessing of the raw count matrices. To do this, either `pagoda2` (default) or `Seurat` can be used. 

```{r}
crm$doPreprocessing()
```

Then, we create the UMAP embedding using `conos`.

```{r}
crm$createEmbedding()
```

We can now plot our cells.

```{r}
crm$plotUmap()
```


# Cell depth

We can plot cell depth, both in the UMAP embedding or as histograms per sample.

```{r}
crm$plotUmap(depth = TRUE, 
             depth.cutoff = 1.5e3)
```

```{r, warning=FALSE}
crm$plotDepth()
```

We can see that the depth distribution varies between samples. We can create a cutoff vector specifying the depth cutoff per sample. It should be a named vector containing sample names.

```{r}
depth_cutoff_vec <- c(1e3,1e3,1e3,1e3,3e3,3.5e3) %>% 
  setNames(crm$detailed_metrics$sample %>% unique() %>% sort())

depth_cutoff_vec
```

Let's plot the updated cutoffs:

```{r, warning=FALSE}
crm$plotDepth(cutoff = depth_cutoff_vec)
```

Also, we can do this in the UMAP embedding:

```{r}
crm$plotUmap(depth = TRUE, 
             depth.cutoff = depth_cutoff_vec)
```

# Doublet detection

For doublet detection, we included the possibility to do so using the Python modules `scrublet` and `DoubletDetection`. If you work on a server using RStudio Server, there may be some preparational steps needed for getting the doublet detection to work. If you are on your own machine, it should be enough to install `reticulate` and the relevant Python module(s).

## Preparations

Install and load `reticulate`, then create a conda environment. In this example, we're on a server and we load `miniconda` using modules. The `conda` parameter should point to wherever your conda binary is located (in terminal, try `whereis conda`)

```{r eval = FALSE}
install.packages("reticulate")
library(reticulate)
conda_create("r-reticulate", 
             conda = "/opt/software/miniconda/4.12.0/condabin/conda", 
             python_version = 3.8)
conda_install("r-reticulate", 
              conda = "/opt/software/miniconda/4.12.0/condabin/conda", 
              pip = TRUE, 
              packages = c("scrublet","doubletdetection"))
```

There is a known problem with openBLAS which may be different between R and Python. If this is the case, you will receive the error `floating point exception` and R will crash when you try to run a Python script using `reticulate`.
In Python, the problem lies within numpy. numba requires numpy < 1.23, so force reinstall from scratch with no binaries in the `r-reticulate` conda environment from terminal
`module load miniconda/4.12.0`
`conda activate r-reticulate`
`python -m pip install numpy==1.22.0 --force-reinstall --no-binary numpy`

Finally, restart your R session.

Please note, if at any point you receive an error that you can't change the current Python instance, please remove any Python-dependent object in your environment and restart your R session.

## Analysis

`scrublet` is the default method, which is fast. `DoubletDetection` is significantly slower, but performs better according to [this](https://www.sciencedirect.com/science/article/pii/S2405471220304592) review. Here, we use `scrublet`.

```{r}
crm$detectDoublets(conda.path = "/opt/software/miniconda/4.12.0/condabin/conda")
```

We can plot the estimated doublets in the UMAP embedding.

```{r}
crm$plotUmap(doublet_method = "scrublet")
```

And we can plot the scores for the doublet estimations.

```{r}
crm$plotUmap(doublet_method = "scrublet", 
             doublet_scores = TRUE)
```

# Mitochondrial fraction

We can also investigate the mitochondrial fraction in our cells

```{r}
crm$plotUmap(mito.frac = TRUE, 
             mito.cutoff = 0.05, 
             species = "human")
```

# Plot filtered cells

We can plot all the cells to be filtered in the UMAP embedding

```{r}
crm$plotFilteredCells(type = "umap", 
                      depth = TRUE, 
                      depth.cutoff = depth_cutoff_vec, 
                      doublet_method = "scrublet", 
                      mito.frac = TRUE, 
                      mito.cutoff = 0.05, 
                      species = "human")
```

And we can plot the cells to be filtered per sample where `combination` means a cell that has at least two filter labels, e.g. `mito` and `depth`.

```{r}
crm$plotFilteredCells(type = "bar", 
                      doublet_method = "scrublet", 
                      depth = TRUE, 
                      depth.cutoff = depth_cutoff_vec, 
                      mito.frac = TRUE, 
                      mito.cutoff = 0.05, 
                      species = "human")
```

We can also extract the raw numbers for plotting in other ways than those included here

```{r}
filter.data <- crm$plotFilteredCells(type = "export")
filter.data %>% head()
```

# Save filtered CMs

Finally, we can filter the count matrices and save them for downstream applications.

```{r eval = FALSE}
crm$filterCms(file = "/data/ExtData/CRMetrics_testdata/cms_filtered.rds", 
              depth_cutoff = depth_cutoff_vec, 
              mito_cutoff = 0.05, 
              species = "human",
              doublets = "scrublet")
```

```{r}
sessionInfo()
```

