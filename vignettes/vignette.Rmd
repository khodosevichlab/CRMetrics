---
title: "Analysis of 10x test data"
output: 
  github_document:
    toc: true
---

# Preparations

We have selected a [publicly available dataset](https://www.ncbi.nlm.nih.gov/geo/) from GEO with accession number GSE179590 which can be downloaded [here](http://kkh.bric.ku.dk/fabienne/crmetrics_testdata.tar.gz). You can download the zipped data using wget or curl, e.g. 
`wget http://kkh.bric.ku.dk/fabienne/crmetrics_testdata.tar.gz`, and then unpack using 
`tar -xvf crmetrics_testdata.tar.gz`

# Using Python modules

We have included several Python modules in this package. If you work on a server using RStudio Server, there may be some preparational steps needed for getting the doublet detection to work. If you are on your own machine, it should be enough to install `reticulate` and the relevant Python module(s).

First, you should install `reticulate`:

```{r, eval=FALSE}
install.packages("reticulate")
library(reticulate)
```


Then you are ready to create a conda environment. In this example, we're on a server and we load `miniconda` using modules. The `conda` parameter should point to wherever your conda binary is located (in terminal, try `whereis conda`)

```{r, eval=FALSE}
conda_create("r-reticulate", 
             conda = "/opt/software/miniconda/4.12.0/condabin/conda", 
             python_version = 3.8)
```

There is a known problem with openBLAS which may be different between R and Python. If this is the case, you will receive the error `floating point exception` and R will crash when you try to run a Python script using `reticulate`.
In Python, the problem lies within numpy. numba requires numpy < 1.23, so force reinstall from scratch with no binaries in the `r-reticulate` conda environment from terminal
`module load miniconda/4.12.0`
`conda activate r-reticulate`
`python -m pip install numpy==1.22.0 --force-reinstall --no-binary numpy`

Finally, restart your R session.

Please note, if at any point you receive an error that you can't change the current Python instance, please remove any Python-dependent object in your environment and restart your R session.

# Initializing a CRMetrics class

Load the library

```{r setup, message=FALSE}
library(CRMetrics)
library(magrittr)
library(dplyr)
```

Initialize a new object of class `CRMetrics` with the path to the Cell Ranger output and a metadata file. Here, the folder with our test data is stored in `/data/ExtData/`.
Metadata can be added in the initialization call from a comma-separated file. The metadata file contains a column `sample` with the samples and optionally more columns with factors. Only sample IDs in column `sample` will be included.

```{r}
crm <- CRMetrics$new(data.path = "/data/ExtData/CRMetrics_testdata/", 
                     metadata = "/data/ExtData/CRMetrics_testdata/metadata.csv", 
                     n.cores = 50)
```

We can review our metadata

```{r}
crm$metadata
```

# Remove ambient RNA

We have added functionality to remove ambient RNA from our samples. This approach should be used with caution since it induces changes to the UMI counts (NB: it does not overwrite the outputs from Cell Ranger).
We have included preparative steps for [CellBender](https://github.com/broadinstitute/CellBender/) as well as incorporated [SoupX](https://github.com/constantAmateur/SoupX) into CRMetrics. 

## CellBender

### Installation

To install, follow [these instructions](https://cellbender.readthedocs.io/en/latest/installation/index.html#manual-installation). It is highly recommended to run `CellBender` using GPU acceleration.
If you are more comfortable installing through `reticulate` in R, these lines should be run:

```{r, eval=FALSE}
library(reticulate)
conda_create("cellbender", 
             conda = "/opt/software/miniconda/4.12.0/condabin/conda", 
             python_version = 3.7)
conda_install("cellbender", 
              conda = "/opt/software/miniconda/4.12.0/condabin/conda", 
              forge = FALSE, 
              channel = "anaconda", 
              packages = "pytables")
conda_install("cellbender", 
              conda = "/opt/software/miniconda/4.12.0/condabin/conda", 
              packages = c("pytorch","torchvision","torchaudio"),
              channel = "pytorch")
```

Then, clone the `CellBender` repository as instructed in the manual. Here, we clone to `/apps/` through `cd /apps/; git clone https://github.com/broadinstitute/CellBender.git` and then `CellBender` can be installed:

```{r, eval=FALSE}
conda_install("cellbender", 
              conda = "/opt/software/miniconda/4.12.0/condabin/conda", 
              pip = TRUE, 
              pip_options = "-e", 
              packages = "/apps/CellBender/")
```

### Analysis

For `CellBender`, we need to specify expected number of cells and total droplets included (please see the [manual](https://cellbender.readthedocs.io/en/latest/usage/index.html) for additional information). As hinted in the manual, the number of total droplets included could be expected number of cells multiplied by 3 (which we set as default). First, we plot these measures:

```{r}
crm$prepareCellbender(shrinkage = 100, # Subsamples every 100th datapoint for faster plotting
                      show.expected.cells = TRUE, 
                      show.total.droplets = TRUE)
```

We could change the total droplets included for any sample. Let us first look at the vector.

```{r}
droplets <- crm$getTotalDroplets()
droplets
```

Then we change the total droplets for SRR15054424.

```{r}
droplets["SRR15054424"] <- 2e4
```

We plot this change.

```{r}
crm$prepareCellbender(shrinkage = 100, 
                      show.expected.cells = TRUE, 
                      show.total.droplets = TRUE, 
                      total.droplets = droplets)
```

We could also multiply expected cells by 4 for all samples and save this in our CRMetrics object.

```{r, eval=FALSE}
crm$cellbender$total.droplets <- crm$getTotalDroplets(multiplier = 4)
```

Finally, we save a script for running `CellBender` on all our samples. Here, we use our modified total droplet vector.

```{r}
crm$saveCellbenderScript(file = "/apps/cellbender_script.sh", 
                         fpr = 0.01, 
                         epochs = 150, 
                         use.gpu = TRUE,
                         total.droplets = droplets)
```

We can run this script in the terminal. Here, we load our miniconda module: `module load miniconda\4.12.0`, we activate the environment: `conda activate cellbender` and we run the bash script: `sh /apps/cellbender_script.sh`

### Plotting

```{r}
crm$plotCbCells()
```

```{r, fig.width = 12, fig.height = 10}
crm$plotCbTraining()
```

```{r, fig.width = 12, fig.height = 10}
crm$plotCbCellProbs()
```

```{r, fig.width = 12, fig.height = 10}
crm$plotCbAmbExp()
```

```{r}
crm$plotCbAmbGenes()
```

## SoupX

The implementation of SoupX uses the automated estimation of contamination and correction.

```{r}
crm$runSoupX()
```

Then, we can plot the corrections.

```{r}
crm$plotSoupX()
```

In the end, we add the SoupX adjusted CMs to our object.

```{r}
crm$addCms(crm$soupx$cms.adj)
```

# Plot summary statistics

We can investigate which metrics are available and choose the ones we would like to plot

```{r}
crm$selectMetrics()
```

## Samples per condition

First, we can plot the number of samples per condition. Here, we investigate how the distribution of the sex differs between the type of MS of the samples where RRMS is short for relapsing remitting MS, and SPMS is short for secondary progressive MS.

```{r warning=FALSE}
crm$plotSummaryMetrics(comp.group = "sex", metrics = "samples per group", second.comp.group = "type")
```

## Metrics per sample

In one plot, we can illustrate selected metric summary stats. If no comparison group is set, it defaults to `sample`. 

```{r fig.width=12, fig.height=12, warning=FALSE}
metrics.to.plot <- crm$selectMetrics(ids = c(1:4,6,18,19))
crm$plotSummaryMetrics(metrics = metrics.to.plot, 
                       plot.geom = "point")
```

## Metrics per condition

We can do the same, but set the comparison group to `type`. This will add statistics to the plots. Additionally, we can add a second comparison group for coloring.

```{r fig.width=12, fig.height=10, warning=FALSE}
crm$addComparison("type")
crm$plotSummaryMetrics(metrics = metrics.to.plot, 
                       plot.geom = "point", 
                       stat.test = "non-parametric",
                       second.comp.group = "sex")
```

## Metrics per condition with >2 levels

For the sake of the example, we change the `RIN` values to `low` (RIN<6), `medium` (6<RIN<7), and `high` (RIN>7). This will provide us with three comparisons groups to exemplify how to use automated statistics for such situations.

```{r, fig.width=12, fig.height=10}
crm$metadata$RIN %<>% 
  as.character() %>% 
  {c("medium","high","high","medium","high","high","low","high")} %>% 
  factor(., levels = c("low", "medium", "high"))

crm$plotSummaryMetrics(comp.group = "RIN",
                       metrics = metrics.to.plot, 
                       plot.geom = "point", 
                       stat.test = "non-parametric",
                       second.comp.group = "type", 
                       secondary.testing = TRUE)
```


## Metrics per condition with numeric covariate

We can choose a numeric comparison group, in this case `age`, which will add regression lines to the plots.

```{r fig.height=10, fig.width=12}
crm$plotSummaryMetrics(comp.group = "age",
                       metrics = metrics.to.plot, 
                       plot.geom = "point",
                       second.comp.group = "type",
                       se = FALSE)
```

If the numeric vector has a significant effect on one of the metrics we can investigate it closer by performing regression analyses for both conditions of `type`.

```{r}
crm$plotSummaryMetrics(comp.group = "age",
                       metrics = "Mean Reads per Cell", 
                       plot.geom = "point",
                       second.comp.group = "type", 
                       group.reg.lines = TRUE)
```

We see that there is no significant effect of the numeric vector on neither of the MS types.

# Add detailed metrics

We can read in count matrices to assess detailed metrics. Otherwise, if count matrices have already been added earlier, this step prepares data for plotting UMI and gene counts.

```{r}
crm$addDetailedMetrics()
```

We plot the detailed metrics. The horizontal lines indicates the median values for all samples.

```{r}
metrics.to.plot <- crm$detailed.metrics$metric %>%
  unique()
crm$plotDetailedMetrics(metrics = metrics.to.plot, 
                        plot.geom = "violin")
```

# Embed cells using Conos and UMAP

In order to plot our cells in a UMAP embedding, we need to perform preprocessing of the raw count matrices. To do this, either `pagoda2` (default) or `Seurat` can be used. 

```{r}
crm$doPreprocessing()
```

Then, we create the UMAP embedding using `conos`.

```{r}
crm$createEmbedding()
```

We can now plot our cells.

```{r}
crm$plotUmap()
```


# Cell depth

We can plot cell depth, both in the UMAP embedding or as histograms per sample.

```{r}
crm$plotUmap(depth = TRUE, 
             depth.cutoff = 1.5e3)
```

```{r, warning=FALSE}
crm$plotDepth()
```

We can see that the depth distribution varies between samples. We can create a cutoff vector specifying the depth cutoff per sample. It should be a named vector containing sample names.

```{r}
depth_cutoff_vec <- c(2.5e3, 2e3, 1e3, 1.5e3, 1.5e3, 2e3, 2.5e3, 2e3) %>% 
  setNames(crm$detailed.metrics$sample %>% unique() %>% sort())

depth_cutoff_vec
```

Let's plot the updated cutoffs:

```{r, warning=FALSE}
crm$plotDepth(cutoff = depth_cutoff_vec)
```

Also, we can do this in the UMAP embedding:

```{r}
crm$plotUmap(depth = TRUE, 
             depth.cutoff = depth_cutoff_vec)
```

# Doublet detection

For doublet detection, we included the possibility to do so using the Python modules `scrublet` and `DoubletDetection`. First, we should install these packages:

```{r, eval = FALSE}
library(reticulate)
conda_install("r-reticulate", 
              conda = "/opt/software/miniconda/4.12.0/condabin/conda", 
              pip = TRUE, 
              packages = c("scrublet","doubletdetection"))
```

`scrublet` is the default method, which is fast. `DoubletDetection` is significantly slower, but performs better according to [this](https://www.sciencedirect.com/science/article/pii/S2405471220304592) review. Here, we run `scrublet` and `DoubletDetection` to compare in the next section.

```{r}
crm$detectDoublets(conda.path = "/opt/software/miniconda/4.12.0/condabin/conda",
                   method = "scrublet")
crm$detectDoublets(conda.path = "/opt/software/miniconda/4.12.0/condabin/conda",
                   method = "doubletdetection")
```

We can plot the estimated doublets in the UMAP embedding.

```{r}
crm$plotUmap(doublet.method = "scrublet")
```

And we can plot the scores for the doublet estimations.

```{r}
crm$plotUmap(doublet.method = "scrublet", 
             doublet.scores = TRUE)
```

## Differences between methods

We can compare how much `scrublet` and `DoubletDetection` overlap in their doublets estimates.
First, let us plot a bar plot of the number of doublets per sample.

```{r}
scrub.res <- crm$doublets$scrublet$result %>% 
  select(labels, sample) %>% 
  mutate(method = "scrublet")
dd.res <- crm$doublets$doubletdetection$result %>% 
  select(labels, sample) %>% 
  mutate(labels = as.logical(labels), 
         method = "DoubletDetection")

dd.res[is.na(dd.res)] <- FALSE

plot.df <- rbind(scrub.res,
                 dd.res) %>% 
  filter(labels) %>% 
  group_by(sample, method) %>% 
  summarise(count = n())

ggplot(plot.df, aes(sample, count, fill = method)) +
  geom_bar(stat = "identity", position = position_dodge()) +
  crm$theme +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5)) +
  labs(x = "", y = "No. doublets", fill = "Method", title = "Doublets per sample")
```

We can also show the total number of doublets detected per method.

```{r}
plot.df %>% 
  group_by(method) %>% 
  summarise(count = sum(count)) %>% 
  ggplot(aes(method, count, fill = method)) + 
  geom_bar(stat = "identity") +
  crm$theme +
  guides(fill = "none") +
  labs(x = "", y = "No. doublets", title = "Total doublets per method")
```

### UMAP

```{r}
plot.vec <- data.frame(scrublet = scrub.res$labels %>% as.numeric(), 
                       doubletdetection = dd.res$labels %>% as.numeric()) %>% 
  apply(1, \(x) if (x[1] == 0 & x[2] == 0) "Kept" else if (x[1] == 1 & x[2] == 0) "scrublet" else if (x[1] == 0 & x[2] == 1) "DoubletDetection" else "Both") %>% 
  setNames(rownames(scrub.res)) %>% 
  factor(levels = c("Kept","scrublet","DoubletDetection","Both"))

crm$con$plotGraph(groups = plot.vec, 
                  mark.groups = FALSE, 
                  show.legend = TRUE, 
                  shuffle.colors = TRUE, 
                  title = "Doublets", 
                  size = 0.3) +
  scale_color_manual(values = c("grey80","red","blue","black"))
```

# Mitochondrial fraction

We can also investigate the mitochondrial fraction in our cells

```{r}
crm$plotUmap(mito.frac = TRUE, 
             mito.cutoff = 0.05, 
             species = "human")
```

# Plot filtered cells

We can plot all the cells to be filtered in the UMAP embedding

```{r}
crm$plotFilteredCells(type = "umap", 
                      depth = TRUE, 
                      depth.cutoff = depth_cutoff_vec, 
                      doublet.method = "scrublet", 
                      mito.frac = TRUE, 
                      mito.cutoff = 0.05, 
                      species = "human")
```

And we can plot the cells to be filtered per sample where `combination` means a cell that has at least two filter labels, e.g. `mito` and `depth`.

```{r}
crm$plotFilteredCells(type = "bar", 
                      doublet.method = "scrublet", 
                      depth = TRUE, 
                      depth.cutoff = depth_cutoff_vec, 
                      mito.frac = TRUE, 
                      mito.cutoff = 0.05, 
                      species = "human")
```

We can also extract the raw numbers for plotting in other ways than those included here

```{r}
filter.data <- crm$plotFilteredCells(type = "export")
filter.data %>% head()
```

# Save filtered CMs

Finally, we can filter the count matrices and save them for downstream applications. Here, we use the `qs` package for saving large files fast.

```{r eval = FALSE}
crm$filterCms(file = "/data/ExtData/CRMetrics_testdata/cms_filtered",
              method = "qs",
              depth.cutoff = depth_cutoff_vec, 
              mito.cutoff = 0.05, 
              doublets = "doubletdetection",
              samples.to.exclude = NULL,
              species = "human")
```

```{r}
sessionInfo()
```
